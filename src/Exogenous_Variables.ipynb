{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T15:51:04.069356Z",
     "start_time": "2019-09-01T15:49:22.228823Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import copy\n",
    "import multiprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try: \n",
    "    __file__\n",
    "except:\n",
    "    curr_dir = os.path.abspath('')\n",
    "else:\n",
    "    curr_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    \n",
    "app_root = curr_dir if os.path.basename(curr_dir) != \"src\" else os.path.dirname(curr_dir)\n",
    "\n",
    "if getpass.getuser() == \"rainfalld\":  # docker daemon\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    destdir = home                    # /var/cache/rainfall-predictor\n",
    "else:\n",
    "    destdir = os.path.join(app_root,'data','manipulated_data')      # non-docker stay in repository\n",
    "\n",
    "\n",
    "file = os.path.join(destdir,'rainfalldata.csv')\n",
    "rd = pd.read_csv(file)\n",
    "file2 = os.path.join(destdir,'ncrainfalldata.csv')\n",
    "ncrd = pd.read_csv(file2)\n",
    "rd.Date = pd.to_datetime(rd.Date)\n",
    "rd = rd.set_index('Date')\n",
    "ncrd.Date = pd.to_datetime(ncrd.Date)\n",
    "ncrd = ncrd.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:30:04.299825Z",
     "start_time": "2019-08-20T10:30:04.206119Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# this cell takes the stored exogen dictionary that is stored in the Data_Wrangling_CAP1 jupyter notebook\n",
    "# that was imported above.\n",
    "try:\n",
    "    %store -r exogen\n",
    "except NameError:\n",
    "    f = open(os.path.join(destdir,\"exogen.json\"),\"r\")\n",
    "    exogen = json.load(f)      # read from file, passed from Data_Wrangling\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T15:51:04.428724Z",
     "start_time": "2019-09-01T15:51:04.413112Z"
    }
   },
   "outputs": [],
   "source": [
    "def sarima_model_creation(data, p, d, q, P, D, Q, m, exog=None):\n",
    "    my_order = [p,d,q]\n",
    "    my_sorder = [P,D,Q,m]\n",
    "    sarimamod = sm.tsa.statespace.SARIMAX(data, exog, order=my_order, seasonal_order=my_sorder, \n",
    "                                          enforce_stationarity=False, enforce_invertibility=False,\n",
    "                                          initialization='approximate_diffuse')\n",
    "    model_fit = sarimamod.fit()# start_params=[0, 0, 0, 0, 1])\n",
    "    return(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T13:02:33.081089Z",
     "start_time": "2019-09-01T13:02:33.034217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function : make forecast based on provided data\n",
    "#\n",
    "# @param train_data --- what I already believe is true.  Dec 2007 and before 80%\n",
    "# @param test_data -- what I want to prove Jan 2008 and up 20%\n",
    "# @param exotrain -- external data not included but could help predictions Dec 2007 and before\n",
    "# @param exotest -- external data I want to prove\n",
    "# @return -- list of all predictions for the location\n",
    "def model_creation_pred_one_step(train_data, test_data, exotrain=None, exotest=None, progress_bar=None):\n",
    "    list_one_step = []\n",
    "    \n",
    "    nextMonth = model_based_forecast(train_data, test_data, exotrain, exotest)\n",
    "    list_one_step.append(nextMonth[0])             # captures prediction\n",
    "    progress_bar.update()\n",
    "\n",
    "    # if test data exists\n",
    "    if len(test_data) > 1:\n",
    "        # increment data for next month's iteration\n",
    "        train_data = pd.concat([train_data, test_data[[0]]])\n",
    "        test_data = test_data.drop(test_data.index[0], axis = 0)\n",
    "        if exotrain is not None:\n",
    "            exotrain = pd.concat([exotrain, exotest.iloc[0]])\n",
    "            exotest = exotest.drop(exotest.index[0], axis = 0)\n",
    "\n",
    "        # execute & capture future predictions\n",
    "        futurePredictions = model_creation_pred_one_step(train_data, test_data, exotrain, exotest, progress_bar)\n",
    "        # add to list\n",
    "        list_one_step.extend(futurePredictions)\n",
    "        \n",
    "    return(list_one_step)\n",
    "\n",
    "# Function : Make forecast from model\n",
    "# @return -- a forecast of next month's rain amount\n",
    "def model_based_forecast(train_data, test_data, exotrain=None, exotest=None):\n",
    "    mod = sarima_model_creation(train_data, 4, 0, 3, 3, 0, 4, 12, exotrain)\n",
    "    # if exists, passing exotrain's prevMonth (december, for forecasting jan), otherwise only forcast based on model\n",
    "    nextMonth = mod.forecast() if exotrain is None else mod.forecast( exotrain.iloc[[-1]] )       # turnary assignment expression\n",
    "    return(nextMonth)\n",
    "\n",
    "# previously billsFn\n",
    "def maeFinder(train_data, test_data, exotrain=None, exotest=None, pbar=None):\n",
    "    clone_train_data = copy.deepcopy(train_data)\n",
    "    clone_test_data = copy.deepcopy(test_data)\n",
    "    clone_exotrain = exotrain if exotrain is None else copy.deepcopy(exotrain)\n",
    "    clone_exotest = exotest if exotest is None else copy.deepcopy(exotest)\n",
    "    \n",
    "    pbar = pbar if pbar is not None else tqdm(total=len(test_data)) # initialize counter\n",
    "    \n",
    "    predictions = model_creation_pred_one_step(clone_train_data, clone_test_data, clone_exotrain, clone_exotest, pbar)\n",
    "    mae = mean_absolute_error(test_data, predictions)\n",
    "    return(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:23:59.034914Z",
     "start_time": "2019-07-31T20:23:59.003666Z"
    }
   },
   "outputs": [],
   "source": [
    "def exog_combinations(df, exoe):\n",
    "    lo_dfs = []\n",
    "    if len(exoe) == 1:\n",
    "        lo_dfs.append(df.loc[:,exoe])\n",
    "    if len(exoe) > 1:\n",
    "        lo_dfs.append(df.loc[:,exoe])\n",
    "        for ex in exoe:\n",
    "            lo_dfs.append(df.loc[:,[ex]])\n",
    "        if len(exoe) >2:\n",
    "            for i in range(2, len(exoe)):\n",
    "                combolist = list(combinations(exoe,i))\n",
    "                for c in combolist:\n",
    "                    lo_dfs.append(df.loc[:,c])\n",
    "    return(lo_dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining set of cities to evaluate\n",
    "if getpass.getuser() == \"rainfalld\":       # docker daemon, automatically do all exogen\n",
    "    todokeys = exogen.keys()\n",
    "else:    # manual setting of dictionary elements to do\n",
    "    todokeys = ('Roanoke Rapids, NC', 'Murfreesboro, NC', 'Lumberton Area, NC', 'LONGWOOD, NC', 'WHITEVILLE 7 NW, NC', 'Charlotte Area, NC', 'Mount Mitchell Area, NC', 'ASHEVILLE AIRPORT, NC', 'BANNER ELK, NC', 'BEECH MOUNTAIN, NC', 'BRYSON CITY 4, NC', 'BREVARD, NC', 'CASAR, NC', 'COWEETA EXP STATION, NC', 'CULLOWHEE, NC', 'FOREST CITY 8 W, NC', 'FRANKLIN, NC', 'GASTONIA, NC', 'GRANDFATHER MTN, NC', ' HENDERSONVILLE 1 NE, NC', ' HIGHLANDS, NC', 'HOT SPRINGS, NC', 'LAKE LURE 2, NC', 'LAKE TOXAWAY 2 SW, NC', 'MARSHALL, NC', 'MONROE 2 SE, NC', ' MOUNT HOLLY 4 NE, NC', ' OCONALUFTEE, NC', 'PISGAH FOREST 3 NE, NC', 'ROBBINSVILLE AG 5 NE, NC', 'ROSMAN, NC', 'SHELBY 2 NW, NC', 'TAPOCO, NC', 'TRYON, NC', 'WAYNESVILLE 1 E, NC', 'Boone 1 SE, NC', 'DANBURY, NC', 'EDEN, NC', ' MOUNT AIRY 2 W, NC', 'REIDSVILLE 2 NW, NC', 'HAYESVILLE 1 NE, NC', 'MURPHY 4ESE, NC', ' KING, NC')\n",
    "\n",
    "sub_exogen = {k: exogen[k] for k in todokeys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:24:01.912170Z",
     "start_time": "2019-07-31T20:24:01.380989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6184a883e0f0447abbd74d3dca8d8f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "l_o_dfs = defaultdict(list)\n",
    "for key,value in tqdm(sub_exogen.items()):\n",
    "    lo_dfs2 = exog_combinations(rd, value)\n",
    "    l_o_dfs[key] = lo_dfs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:24:07.727065Z",
     "start_time": "2019-07-31T20:24:07.695861Z"
    }
   },
   "outputs": [],
   "source": [
    "def exogenous_var(data, ncloc, l_exoloc):\n",
    "    dat = data[ncloc]\n",
    "    tr, test = train_test_split(dat, test_size=0.2, shuffle=False)\n",
    "    keymae = maeFinder(tr, test)\n",
    "    print('keymae of: '+ key +' = '+str(keymae))\n",
    "    bettermae = {}\n",
    "    bettermaeLock = multiprocessing.Lock()\n",
    "    \n",
    "    def on_success(result):\n",
    "        print('exmae = {}'.format(result[\"co\"]) + ' '+ str(result[\"exmae\"]))\n",
    "        progressbar.update() # update counter of completion\n",
    "    \n",
    "    def on_error(err):\n",
    "        print(err)\n",
    "        pass\n",
    "    \n",
    "    process_limit = multiprocessing.cpu_count()\n",
    "    progressbar = tqdm(total=len(l_exoloc))  # initialize counter (regular)\n",
    "#     progressbar = tqdm(total=(len(l_exoloc)*len(test))) # initialize counter (multiple exmaes at once, fails do to process collision)\n",
    "    pool = multiprocessing.Pool(processes=process_limit, initializer=init, initargs=(bettermaeLock, keymae, tr, test, l_exoloc, progressbar))\n",
    "    for exog in l_exoloc:\n",
    "        pool.apply_async(find_exmae, args=(exog, bettermae), kwds={}, callback=on_success, error_callback=on_error)\n",
    "    \n",
    "    pool.close()      # no more tasks can be added for the pool to accomplish\n",
    "    pool.join()       # tell parent to wait until all tasks are accomplished by the process pool\n",
    "\n",
    "    return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_exmae(exog, bettermae):\n",
    "    extr, extest = train_test_split(exog, test_size=0.2, shuffle=False)\n",
    "    exmae = maeFinder(tr, test, extr, extest, pbar)\n",
    "    co = tuple(exog.columns)\n",
    "    if exmae < keymae:\n",
    "        lock.acquire()\n",
    "        try:\n",
    "            bettermae[co] = exmae\n",
    "            bettermae2 = {key: bettermae}\n",
    "        finally:\n",
    "            lock.release()\n",
    "        \n",
    "    return { \"co\": co, \"exmae\": exmae }\n",
    "\n",
    "def init(l, kmae, train, testing, list_exoloc, progress_bar):\n",
    "    global lock\n",
    "    global keymae\n",
    "    global tr\n",
    "    global test\n",
    "    global l_exoloc\n",
    "    global pbar\n",
    "    lock = l\n",
    "    keymae = kmae\n",
    "    tr = train\n",
    "    test = testing\n",
    "    l_exoloc = list_exoloc\n",
    "    pbar = progress_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_comb = [[4,3,3,4]]\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for key,value in tqdm(l_o_dfs.items()):\n",
    "    exogenous_var(rd, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_exogs = ['WHITEVILLE 7 NW, NC', 'CASAR, NC', 'FOREST CITY 8 W, NC', 'GASTONIA, NC', 'LAKE LURE 2, NC', \n",
    "                       'ELIZABETHTOWN, NC', ' MOUNT HOLLY 4 NE, NC','GRANDFATHER MTN, NC']\n",
    "ncrd2 = ncrd.copy()\n",
    "ncrd_less = ncrd2.drop(with_exogs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fx(data, begin, end):\n",
    "    base = datetime.strptime(begin,'%Y-%m-%d')\n",
    "    date_list = [base + relativedelta(months=x) for x in range(600)]\n",
    "    prediction1_df = pd.DataFrame(index=date_list)\n",
    "    for col in tqdm(data.columns):\n",
    "        loc = data[col]\n",
    "        mod_fit1 = sarima_model_creation(loc, 4,0,3,3,0,4,12)\n",
    "        point_predictions = pd.DataFrame(mod_fit1.predict(start=begin, end=end), columns=[col])\n",
    "        future_pred1 = mod_fit1.get_prediction(start=begin, end=end)\n",
    "        future_pred1_ci = future_pred1.conf_int(alpha=0.5)\n",
    "        point_predictions_df = pd.merge(point_predictions, future_pred1_ci, left_index=True, right_index=True)\n",
    "        prediction1_df = pd.merge(prediction1_df, point_predictions_df, left_index=True, right_index=True)\n",
    "    return(prediction1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = prediction_fx(ncrd_less, '2019-05-01', '2069-05-01')\n",
    "pre_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_var_dict2 = {\n",
    "    'WHITEVILLE 7 NW, NC': rd[[' LORIS 2 S, SC']],\n",
    "    'CASAR, NC': rd[['GAFFNEY 6 E, SC']],\n",
    "    'FOREST CITY 8 W, NC': rd[['GAFFNEY 6 E, SC']],\n",
    "    'GASTONIA, NC': rd[['FORT MILL 4 NW, SC','GAFFNEY 6 E, SC']],\n",
    "    'LAKE LURE 2, NC': rd[['CHESNEE 7 WSW, SC']],\n",
    "    ' MOUNT HOLLY 4 NE, NC': rd[['CHESNEE 7 WSW, SC','GAFFNEY 6 E, SC']],\n",
    "    'ELIZABETHTOWN, NC': rd[[' LORIS 2 S, SC']],\n",
    "    'GRANDFATHER MTN, NC': rd[['ELIZABETHTON, TN']]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_exog_fx2(data, exog_dict, begin, end):\n",
    "    base = datetime.strptime(begin,'%Y-%m-%d')\n",
    "    date_list = [base + relativedelta(months=x) for x in range(600)]\n",
    "    prediction_df = pd.DataFrame(index = date_list)\n",
    "    pred_val_df = pd.DataFrame(index = date_list)\n",
    "    exog_predictions_df = pd.DataFrame(index = date_list)\n",
    "    for key,value in tqdm(exog_dict.items()):\n",
    "        loc = data[key]\n",
    "        mod_fit1 = sarima_model_creation(loc, 4,0,3,3,0,4, 12,exog=value)\n",
    "        if value.shape[1] > 1:\n",
    "            shap = value.shape[1]\n",
    "            for i in range(shap):\n",
    "                exog_mod_fit = sarima_model_creation(value.iloc[:,i],4,0,3,3,0,4,12)\n",
    "                e_preds2 = pd.DataFrame(exog_mod_fit.predict(start=begin, end=end))\n",
    "                if i is 0:\n",
    "                    exog_predictions_df = e_preds2\n",
    "                else:\n",
    "                    exog_predictions_df = pd.merge(exog_predictions_df, e_preds2, left_index=True, \n",
    "                                                   right_index=True)\n",
    "        else:\n",
    "            exog_mod_fit = sarima_model_creation(value, 4,0,3,3,0,4,12)\n",
    "            exog_predictions_df = pd.DataFrame(exog_mod_fit.predict(start=begin, end=end))\n",
    "        future_pred = mod_fit1.get_prediction(exog=exog_predictions_df,start=begin, end=end)\n",
    "        future_pred_ci = future_pred.conf_int(alpha=0.5)\n",
    "        future_pred_val= pd.DataFrame(mod_fit1.predict(exog=exog_predictions_df, start=begin, end=end), \n",
    "                                      columns = [key])\n",
    "        future_pred_full = pd.merge(future_pred_val, future_pred_ci, left_index=True, right_index=True)\n",
    "        prediction_df = pd.merge(prediction_df, future_pred_full, left_index=True, right_index=True)\n",
    "    return(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ci_df = prediction_exog_fx2(rd, exo_var_dict2, '2019-05-01', '2069-05-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_ci_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ci_vals = pd.merge(pre_df, e_ci_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ci_vals.to_csv('../data/manipulated_data/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ci_vals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
